{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Keras Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow transformers nobuco\n",
    "\n",
    "# required install torch on https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nobuco\n",
    "from nobuco import ChannelOrder, ChannelOrderingStrategy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from model import Mamba, ModelArgs\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nobuco.converter(F.softplus, channel_ordering_strategy=ChannelOrderingStrategy.MINIMUM_TRANSPOSITIONS)\n",
    "def softplus(input: torch.Tensor):\n",
    "    return lambda input: tf.keras.activations.softplus(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nobuco.converter(torch.einsum, channel_ordering_strategy=ChannelOrderingStrategy.FORCE_PYTORCH_ORDER)\n",
    "def converter_einsum(*args):\n",
    "    def func(*args):\n",
    "        equation = args[0]\n",
    "        operands = args[1:]\n",
    "        return tf.einsum(equation, *operands)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 19:47:13.408601: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-19 19:47:13.409221: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-02-19 19:47:13.481166: I external/local_xla/xla/service/service.cc:168] XLA service 0xea8a220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-19 19:47:13.481192: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708368433.488287   28138 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-02-19 19:47:13.488457: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mMamba[model]\u001b[0m(int64_0<1,1>\u001b[0m) -> float32_87<1,1,50280>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mEmbedding[torch.nn.modules.sparse]\u001b[0m(int64_0<1,1>\u001b[0m) -> float32_2<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1membedding[torch.nn.functional]\u001b[0m(int64_0<1,1>\u001b[0m, \u001b[4mfloat32_1<50280,5>\u001b[0m, None, None, 2.0, False, False) -> float32_2<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mResidualBlock[model]\u001b[0m(float32_2<1,1,5>\u001b[0m) -> float32_79<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mRMSNorm[model]\u001b[0m(float32_2<1,1,5>\u001b[0m) -> float32_9<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpow[torch.Tensor]\u001b[0m(float32_2<1,1,5>\u001b[0m, 2) -> float32_3<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mmean[torch.Tensor]\u001b[0m(float32_3<1,1,5>\u001b[0m, -1, keepdim=True) -> float32_4<1,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_4<1,1,1>\u001b[0m, 1e-05) -> float32_5<1,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mrsqrt[torch]\u001b[0m(float32_5<1,1,1>\u001b[0m) -> float32_6<1,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_2<1,1,5>\u001b[0m, float32_6<1,1,1>\u001b[0m) -> float32_7<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_7<1,1,5>\u001b[0m, \u001b[4mfloat32_8<5>\u001b[0m) -> float32_9<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mMambaBlock[model]\u001b[0m(float32_9<1,1,5>\u001b[0m) -> float32_78<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco]\u001b[0m(float32_9<1,1,5>\u001b[0m) -> (\u001b[90mint32_10<>\u001b[0m, int32_11<>\u001b[0m, \u001b[90mint32_12<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_9<1,1,5>\u001b[0m) -> float32_14<1,1,20>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_9<1,1,5>\u001b[0m, float32_13<20,5>\u001b[0m, None) -> float32_14<1,1,20>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msplit[torch.Tensor]\u001b[0m(float32_14<1,1,20>\u001b[0m, split_size=[10, 10], dim=-1) -> (float32_15<1,1,10>\u001b[0m, float32_16<1,1,10>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco]\u001b[0m(float32_15<1,1,10>\u001b[0m) -> (\u001b[90mint32_17<>\u001b[0m, \u001b[90mint32_18<>\u001b[0m, \u001b[90mint32_19<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco]\u001b[0m(float32_15<1,1,10>\u001b[0m) -> (int32_20<>\u001b[0m, int32_21<>\u001b[0m, int32_22<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__rmul__[torch.Tensor]\u001b[0m(int32_20<>\u001b[0m, 1) -> \u001b[90mint32_23<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__rmul__[torch.Tensor]\u001b[0m(int32_22<>\u001b[0m, 1) -> \u001b[90mint32_24<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__rmul__[torch.Tensor]\u001b[0m(int32_21<>\u001b[0m, 1) -> \u001b[90mint32_25<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_15<1,1,10>\u001b[0m, [0, 2, 1]) -> float32_26<1,10,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv1d[torch.nn.modules.conv]\u001b[0m(float32_26<1,10,1>\u001b[0m) -> float32_29<1,10,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv1d[torch.nn.functional]\u001b[0m(float32_26<1,10,1>\u001b[0m, float32_27<10,1,4>\u001b[0m, float32_28<10>\u001b[0m, (1), (3), (1), 10) -> float32_29<1,10,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_29<1,10,4>\u001b[0m, (:, :, :int32_11<>\u001b[0m)) -> float32_30<1,10,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco]\u001b[0m(float32_30<1,10,1>\u001b[0m) -> (\u001b[90mint32_31<>\u001b[0m, \u001b[90mint32_32<>\u001b[0m, \u001b[90mint32_33<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco]\u001b[0m(float32_30<1,10,1>\u001b[0m) -> (int32_34<>\u001b[0m, int32_35<>\u001b[0m, int32_36<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__rmul__[torch.Tensor]\u001b[0m(int32_34<>\u001b[0m, 1) -> \u001b[90mint32_37<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__rmul__[torch.Tensor]\u001b[0m(int32_36<>\u001b[0m, 1) -> \u001b[90mint32_38<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__rmul__[torch.Tensor]\u001b[0m(int32_35<>\u001b[0m, 1) -> \u001b[90mint32_39<>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpermute[torch.Tensor]\u001b[0m(float32_30<1,10,1>\u001b[0m, [0, 2, 1]) -> float32_40<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msilu[torch.nn.functional]\u001b[0m(float32_40<1,1,10>\u001b[0m) -> float32_41<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco]\u001b[0m(\u001b[4mfloat32_42<10,16>\u001b[0m) -> (int32_43<>\u001b[0m, int32_44<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mfloat[torch.Tensor]\u001b[0m(\u001b[4mfloat32_42<10,16>\u001b[0m) -> float32_42<10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mexp[torch]\u001b[0m(\u001b[4mfloat32_42<10,16>\u001b[0m) -> float32_45<10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mneg[torch.Tensor]\u001b[0m(float32_45<10,16>\u001b[0m) -> float32_46<10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mfloat[torch.Tensor]\u001b[0m(\u001b[4mfloat32_47<10>\u001b[0m) -> float32_47<10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_41<1,1,10>\u001b[0m) -> float32_49<1,1,33>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_41<1,1,10>\u001b[0m, float32_48<33,10>\u001b[0m, None) -> float32_49<1,1,33>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msplit[torch.Tensor]\u001b[0m(float32_49<1,1,33>\u001b[0m, split_size=[1, int32_44<>\u001b[0m, int32_44<>\u001b[0m], dim=-1) -> (float32_50<1,1,1>\u001b[0m, float32_51<1,1,16>\u001b[0m, float32_52<1,1,16>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_50<1,1,1>\u001b[0m) -> float32_55<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_50<1,1,1>\u001b[0m, float32_53<10,1>\u001b[0m, float32_54<10>\u001b[0m) -> float32_55<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msoftplus[torch.nn.functional]\u001b[0m(float32_55<1,1,10>\u001b[0m) -> float32_56<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco]\u001b[0m(float32_41<1,1,10>\u001b[0m) -> (int32_57<>\u001b[0m, \u001b[90mint32_58<>\u001b[0m, int32_59<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mshape[nobuco]\u001b[0m(float32_46<10,16>\u001b[0m) -> (int32_60<>\u001b[0m, int32_61<>\u001b[0m)\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1meinsum[torch]\u001b[0m(\"abc,cd->abcd\", float32_56<1,1,10>\u001b[0m, float32_46<10,16>\u001b[0m) -> float32_62<1,1,10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mexp[torch]\u001b[0m(float32_62<1,1,10,16>\u001b[0m) -> float32_63<1,1,10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1meinsum[torch]\u001b[0m(\"abc,abd,abc->abcd\", float32_56<1,1,10>\u001b[0m, float32_51<1,1,16>\u001b[0m, float32_41<1,1,10>\u001b[0m) -> float32_64<1,1,10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mzeros[torch]\u001b[0m((int32_57<>\u001b[0m, int32_59<>\u001b[0m, int32_61<>\u001b[0m), device=cpu) -> float32_65<1,10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_63<1,1,10,16>\u001b[0m, (:, 0)) -> float32_66<1,10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_66<1,10,16>\u001b[0m, float32_65<1,10,16>\u001b[0m) -> float32_67<1,10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_64<1,1,10,16>\u001b[0m, (:, 0)) -> float32_68<1,10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_67<1,10,16>\u001b[0m, float32_68<1,10,16>\u001b[0m) -> float32_69<1,10,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__getitem__[TensorBase]\u001b[0m(float32_52<1,1,16>\u001b[0m, (:, 0, :)) -> float32_70<1,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1meinsum[torch]\u001b[0m(\"abc,ac->ab\", float32_69<1,10,16>\u001b[0m, float32_70<1,16>\u001b[0m) -> float32_71<1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mstack[torch]\u001b[0m([float32_71<1,10>\u001b[0m], dim=1) -> float32_72<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_41<1,1,10>\u001b[0m, \u001b[4mfloat32_47<10>\u001b[0m) -> float32_73<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_72<1,1,10>\u001b[0m, float32_73<1,1,10>\u001b[0m) -> float32_74<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msilu[torch.nn.functional]\u001b[0m(float32_16<1,1,10>\u001b[0m) -> float32_75<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_74<1,1,10>\u001b[0m, float32_75<1,1,10>\u001b[0m) -> float32_76<1,1,10>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_76<1,1,10>\u001b[0m) -> float32_78<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_76<1,1,10>\u001b[0m, float32_77<5,10>\u001b[0m, None) -> float32_78<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_78<1,1,5>\u001b[0m, float32_2<1,1,5>\u001b[0m) -> float32_79<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mRMSNorm[model]\u001b[0m(float32_79<1,1,5>\u001b[0m) -> float32_86<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mpow[torch.Tensor]\u001b[0m(float32_79<1,1,5>\u001b[0m, 2) -> float32_80<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mmean[torch.Tensor]\u001b[0m(float32_80<1,1,5>\u001b[0m, -1, keepdim=True) -> float32_81<1,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_81<1,1,1>\u001b[0m, 1e-05) -> float32_82<1,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mrsqrt[torch]\u001b[0m(float32_82<1,1,1>\u001b[0m) -> float32_83<1,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_79<1,1,5>\u001b[0m, float32_83<1,1,1>\u001b[0m) -> float32_84<1,1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_84<1,1,5>\u001b[0m, \u001b[4mfloat32_85<5>\u001b[0m) -> float32_86<1,1,5>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_86<1,1,5>\u001b[0m) -> float32_87<1,1,50280>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_86<1,1,5>\u001b[0m, float32_1<50280,5>\u001b[0m, None) -> float32_87<1,1,50280>\u001b[0m\n",
      "\n",
      "Conversion complete. Elapsed time: 0.78 sec.\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(\n",
    "    d_model=5,\n",
    "    n_layer=1,\n",
    "    vocab_size=50277\n",
    ")\n",
    "model = Mamba(args)\n",
    "model.eval()\n",
    "export_name = \"mamba_minimal_1_layer\"\n",
    "dummy_input = \"Test\"\n",
    "input_ids = tokenizer(dummy_input, return_tensors='pt').input_ids\n",
    "\n",
    "keras_model = nobuco.pytorch_to_keras(\n",
    "    model,\n",
    "    args=[input_ids], kwargs=None,\n",
    "    input_shapes={input_ids: (1, None)}, # Annotate dynamic axes with None\n",
    "    inputs_channel_order=ChannelOrder.TENSORFLOW,\n",
    "    outputs_channel_order=ChannelOrder.TENSORFLOW,\n",
    "    constants_to_variables=False,\n",
    "    trace_shape=True,\n",
    "    save_trace_html=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(keras_model, f'{export_name}.keras')\n",
    "tf.keras.models.save_model(keras_model, f'{export_name}.h5')\n",
    "tf.saved_model.save(keras_model, f'{export_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[[-3.0078745   3.9671001  -2.305275  ]\n",
      "  [-1.5027751  -1.864156    2.8154929 ]\n",
      "  [-2.2186959   5.2344885  -1.0442678 ]\n",
      "  ...\n",
      "  [-4.8536053   5.0152903  -3.8399842 ]\n",
      "  [-0.11023474  0.26254967  2.5834856 ]\n",
      "  [ 1.321992   -1.8405054  -1.6095277 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Inference Test for nobuco converted model\n",
    "# prompt\n",
    "dummy_prompt_keras = \"Harry Potter test\"\n",
    "input_ids_keras = tokenizer(dummy_prompt_keras, return_tensors='tf').input_ids\n",
    "\n",
    "#input_ids_keras = tf.cast(input_ids_keras, tf.int64)\n",
    "# inference\n",
    "out = keras_model.predict(input_ids_keras)\n",
    "# output\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SavedModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 2.1814482   5.0091105 ]\n",
      "  [-0.9071193  -2.4775052 ]\n",
      "  [-2.2117083  -0.39902794]\n",
      "  ...\n",
      "  [-0.49433738  1.2557342 ]\n",
      "  [-2.74676    -0.9496337 ]\n",
      "  [ 1.0100164  -4.3799496 ]]], shape=(1, 50280, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "dummy_prompt_keras = \"Harry Potter\"\n",
    "input_ids_keras = tokenizer(dummy_prompt_keras, return_tensors='tf').input_ids\n",
    "\n",
    "# loading model\n",
    "export_path = \"mamba_minimal_1_layer\" # No '.h5' in the path!\n",
    "keras_model_restored = tf.saved_model.load(export_path)\n",
    "\n",
    "input_ids_keras = tf.cast(input_ids_keras, tf.int64)\n",
    "\n",
    "# inference\n",
    "out = keras_model_restored(input_ids_keras)\n",
    "\n",
    "# output\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"lambda_12\" (type Lambda).\n\n'list' object has no attribute 'shape'\n\nCall arguments received by layer \"lambda_12\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(1, None, 10), dtype=float32)', [['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]]\n  • mask=None\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# loading model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m export_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmamba_minimal_1_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m keras_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaving\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexport_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m input_ids_keras \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(input_ids_keras, tf\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# inference\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/saving/saving_api.py:254\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    264\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:281\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    278\u001b[0m             asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:246\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 246\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:728\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m safe_mode_scope \u001b[38;5;241m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[0;32m--> 728\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m     build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m build_config:\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/engine/training.py:3330\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3322\u001b[0m revivable_as_functional \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3323\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {functional\u001b[38;5;241m.\u001b[39mFunctional, Model}\n\u001b[1;32m   3324\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m functional_init_args\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (argspec\u001b[38;5;241m.\u001b[39mvarargs \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39mvarkw \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3326\u001b[0m )\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m   3328\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m   3329\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[0;32m-> 3330\u001b[0m     inputs, outputs, layers \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m   3332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3333\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   3334\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3335\u001b[0m     )\n\u001b[1;32m   3336\u001b[0m     functional\u001b[38;5;241m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/engine/functional.py:1505\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m layer_nodes:\n\u001b[1;32m   1504\u001b[0m     node_data \u001b[38;5;241m=\u001b[39m layer_nodes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1506\u001b[0m         layer_nodes\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m         \u001b[38;5;66;03m# If a node can't be processed, stop processing the\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;66;03m# nodes of the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/engine/functional.py:1445\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_preserve_input_structure_in_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_preserve_input_structure_in_config\n\u001b[1;32m   1441\u001b[0m ):\n\u001b[1;32m   1442\u001b[0m     input_tensors \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39munnest_if_single_tensor(\n\u001b[1;32m   1443\u001b[0m         input_tensors\n\u001b[1;32m   1444\u001b[0m     )\n\u001b[0;32m-> 1445\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;66;03m# Update node index map.\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m output_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output_tensors)[\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1450\u001b[0m ]\u001b[38;5;241m.\u001b[39m_keras_history\u001b[38;5;241m.\u001b[39mnode_index\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/nobuco/node_converters/linear.py:102\u001b[0m, in \u001b[0;36mconverter_einsum.<locals>.func.<locals>.<lambda>\u001b[0;34m(operands)\u001b[0m\n\u001b[1;32m    100\u001b[0m equation \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m operands \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m operands: \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m)(operands)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling layer \"lambda_12\" (type Lambda).\n\n'list' object has no attribute 'shape'\n\nCall arguments received by layer \"lambda_12\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(1, None, 10), dtype=float32)', [['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]]\n  • mask=None\n  • training=None"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "dummy_prompt_keras = \"Harry Potter\"\n",
    "input_ids_keras = tokenizer(dummy_prompt_keras, return_tensors='tf').input_ids\n",
    "\n",
    "# loading model\n",
    "export_name = \"mamba_minimal_1_layer\"\n",
    "keras_model = tf.keras.saving.load_model (f'{export_name}.keras', safe_mode=False)\n",
    "\n",
    "input_ids_keras = tf.cast(input_ids_keras, tf.int64)\n",
    "\n",
    "# inference\n",
    "out = keras_model.predict(input_ids_keras)\n",
    "\n",
    "# output\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"lambda_12\" (type Lambda).\n\n'list' object has no attribute 'shape'\n\nCall arguments received by layer \"lambda_12\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(1, None, 10), dtype=float32)', [['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]]\n  • mask=None\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# loading model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m export_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmamba_minimal_1_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m keras_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaving\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexport_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m input_ids_keras \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(input_ids_keras, tf\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# inference\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/saving/saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    255\u001b[0m         filepath,\n\u001b[1;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.11/site-packages/nobuco/node_converters/linear.py:102\u001b[0m, in \u001b[0;36mconverter_einsum.<locals>.func.<locals>.<lambda>\u001b[0;34m(operands)\u001b[0m\n\u001b[1;32m    100\u001b[0m equation \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m operands \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m operands: \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m)(operands)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling layer \"lambda_12\" (type Lambda).\n\n'list' object has no attribute 'shape'\n\nCall arguments received by layer \"lambda_12\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(1, None, 10), dtype=float32)', [['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]]\n  • mask=None\n  • training=None"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "dummy_prompt_keras = \"Harry Potter\"\n",
    "input_ids_keras = tokenizer(dummy_prompt_keras, return_tensors='tf').input_ids\n",
    "\n",
    "# loading model\n",
    "export_name = \"mamba_minimal_1_layer\"\n",
    "keras_model = tf.keras.saving.load_model (f'{export_name}.h5')\n",
    "\n",
    "input_ids_keras = tf.cast(input_ids_keras, tf.int64)\n",
    "\n",
    "# inference\n",
    "out = keras_model.predict(input_ids_keras)\n",
    "\n",
    "# output\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
